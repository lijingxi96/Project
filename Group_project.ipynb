{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpareRoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from jinja2->folium)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->folium)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->folium)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->folium)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->folium)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Web Scraping housing info in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housings(url): \n",
    "    housings_list = list()\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Request for home page of NY housing info\n",
    "    try:\n",
    "        results_page = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(results_page.content,'lxml')\n",
    "    except:\n",
    "        return None\n",
    "    # Get all the feature housings and bold housings on the first page\n",
    "    feature_housings = soup.find_all('article',class_='panel-listing-result listing-featured ')\n",
    "    for housing in feature_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "    # Second Type of housing\n",
    "    all_housings = soup.find_all('article', class_='panel-listing-result listing-bold ')\n",
    "    for housing in all_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "    # Third type of housing:\n",
    "    early_bird_housings = soup.find_all('article', class_='panel-listing-result listing-free ')\n",
    "    for housing in early_bird_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "#     Turn to next page and get more housings\n",
    "    if soup.find('ul',class_='navnext'):\n",
    "        if soup.find('ul',class_='navnext').find('a'):\n",
    "            next_page_token = soup.find('ul',class_='navnext').find('a').get('href')\n",
    "            next_page = 'https://www.spareroom.co.uk/flatshare/' + next_page_token\n",
    "        # Use recursion to get all the attractions    \n",
    "            housings_list.extend(get_housings(next_page))\n",
    "    return housings_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_london = 'https://www.spareroom.co.uk/flatshare/?search_id=745817425&'\n",
    "list_ = get_housings(url_london)\n",
    "print(f'We have find {len(list_)} results for you.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(list_housings):\n",
    "    count = 0 \n",
    "    full_dict = dict()\n",
    "    for dict_info, link in list_housings:\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        # Request for details of each housing in NY\n",
    "        try:\n",
    "            results_page = requests.get(link)\n",
    "        except:\n",
    "            return None\n",
    "        try:\n",
    "            soup = BeautifulSoup(results_page.content,'lxml')\n",
    "        except:\n",
    "            return None\n",
    "        # Get housing price for each room \n",
    "        price_list = list()\n",
    "        if soup.find('ul', class_='room-list'): \n",
    "            prices = soup.find('ul', class_='room-list')\n",
    "            price = prices.find_all('strong', class_='room-list__price')\n",
    "            for price_i in price:\n",
    "                price_list.append(price_i.get_text())\n",
    "        # price 这里似乎有个bug，但是我暂时懒得改\n",
    "        if soup.find('h3', class_='feature__heading'):\n",
    "            price_list.append(soup.find('h3', class_='feature__heading').get_text())\n",
    "        # Clean the data to remove 'Availability' in the price list\n",
    "        if 'Availability' in price_list:\n",
    "            price_list.remove('Availability')\n",
    "        dict_info['Price'] = price_list\n",
    "        # Get Availability for each housing\n",
    "        avail = soup.find('section', class_='feature feature--availability')\n",
    "        if avail:\n",
    "            all_info_avail = avail.find_all('dd', class_='feature-list__value')\n",
    "            availablility = all_info_avail[0].get_text()      \n",
    "            min_period = all_info_avail[1].get_text()      \n",
    "            max_period = all_info_avail[2].get_text() \n",
    "            dict_info['Availablility'] = availablility\n",
    "            dict_info['Min_period'] = min_period\n",
    "            dict_info['Max_period'] = max_period\n",
    "        # Get Amenities info for each housing\n",
    "        amenities = soup.find('section', class_='feature feature--amenities')\n",
    "        if amenities:\n",
    "            all_info_amenities = amenities.find_all('dd', class_='feature-list__value')\n",
    "            if all_info_amenities:\n",
    "                furnish = all_info_amenities[0].get_text()\n",
    "                dict_info['Furnishing'] = furnish\n",
    "        else:\n",
    "            dict_info['Furnishing'] = 'No info'\n",
    "        # Female/Male requirement\n",
    "        preference = soup.find('section', class_='feature feature--household-preferences')\n",
    "        if preference:\n",
    "            preference_info = preference.find_all('dt', class_='feature-list__key')\n",
    "            preference_detail = preference.find_all('dd', class_='feature-list__value')\n",
    "            if preference_info and preference_detail:\n",
    "                for info in preference_info:\n",
    "                    if info.get_text() == 'Gender':\n",
    "                        info_index = preference_info.index(info)\n",
    "                        break\n",
    "                try:\n",
    "                    gender = preference_detail[info_index].get_text() \n",
    "                    dict_info['Gender_requirement'] = gender\n",
    "                except:\n",
    "                    dict_info['Gender_requirement'] = 'No info'\n",
    "        full_dict[count] = dict_info\n",
    "        count = count + 1\n",
    "    return full_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_housings = list_\n",
    "dict_ = get_details(list_housings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_.keys():\n",
    "    for subkey in dict_[key].keys():\n",
    "        if isinstance(dict_[key][subkey], str):\n",
    "            dict_[key][subkey] = dict_[key][subkey].lstrip().rstrip()\n",
    "# Clean the price list\n",
    "for key in dict_.keys():\n",
    "    list_in = list()\n",
    "    for item in list(dict_[key]['Price']):\n",
    "        list_in.append(item.strip('\\n'))\n",
    "    dict_[key]['Price'] = list_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create a dataframe to store the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(dict_)\n",
    "df_info = df_info.T\n",
    "\n",
    "# Fix furnished problem\n",
    "for i in df_info.index:\n",
    "    if df_info.iloc[i]['Furnishing'] in ['Furnished', 'Part Furnished', 'Unfurnished']:\n",
    "        pass\n",
    "    else:\n",
    "        df_info.iloc[i]['Furnishing'] = 'No info'\n",
    "# Fix Gender_requirement problem\n",
    "for i in df_info.index:\n",
    "    if not df_info.iloc[i]['Gender_requirement'] in ['Males or females', 'Female preferred', 'No info',\n",
    "       'Male preferred']:\n",
    "        df_info.iloc[i]['Gender_requirement'] = 'No info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new col in df_info to store average price for a single person\n",
    "pattern = r'\\d+'  \n",
    "price_per_month = list()\n",
    "\n",
    "for i in df_info.index:\n",
    "    list_in_price = list()\n",
    "    for item in df_info.iloc[i]['Price']:\n",
    "        item = item.replace(',', '')\n",
    "        if 'pw' in item:\n",
    "            price_info = int((re.findall(pattern, item))[0])\n",
    "            list_in_price.append(price_info*4)\n",
    "        if 'pcm' in item:\n",
    "            price_info = int((re.findall(pattern, item))[0])\n",
    "            list_in_price.append(price_info)\n",
    "    price_per_month.append(list_in_price)\n",
    "price_per_month = np.array(price_per_month)\n",
    "df_info['Price_per_month'] = price_per_month\n",
    "list_avg_price = list()\n",
    "for i in df_info.index:\n",
    "    list_avg_price.append(np.mean(df_info.iloc[i]['Price_per_month']) )\n",
    "df_info['Average_price_per_month'] = np.array(list_avg_price)\n",
    "# Create a new col in df_info to store zip code for each housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new col for zip code\n",
    "list_pos = list()\n",
    "for i in df_info.index:\n",
    "    for s in df_info.iloc[i]['Location']:\n",
    "        if s == '(':\n",
    "            position = df_info.iloc[i]['Location'].index(s)\n",
    "            break\n",
    "    list_pos.append(df_info.iloc[i]['Location'][position:].strip('(').strip(')'))\n",
    "df_info['Postal_code'] = np.array(list_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')# seaborn is a style that have different colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see if there is a gender preference in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group = df_info.groupby('Gender_requirement')\n",
    "gender_group.size().plot(kind='bar', title='Gender requirement for rent in London')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see the housing condition in postal code area in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Postal_code_group = df_info.groupby('Postal_code')\n",
    "Postal_code_group.size().plot(kind='bar', title='Postal code area in London', figsize=(24,24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see if there is more furnished apartment in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furnish_group = df_info.groupby('Furnishing')\n",
    "furnish_group.size().plot(kind='bar', title='Furnishing status of housing in London')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see the size distribution in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_group = df_info.groupby('Size')\n",
    "size_group.size().plot(kind='bar', title='Housing size in London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Liverpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housings(url): \n",
    "    housings_list = list()\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Request for home page of NY housing info\n",
    "    try:\n",
    "        results_page = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(results_page.content,'lxml')\n",
    "    except:\n",
    "        return None\n",
    "    # Get all the feature housings and bold housings on the first page\n",
    "    feature_housings = soup.find_all('article',class_='panel-listing-result listing-featured ')\n",
    "    for housing in feature_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "    # Second type\n",
    "    all_housings = soup.find_all('article', class_='panel-listing-result listing-bold ')\n",
    "    for housing in all_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "    # Third type\n",
    "    early_bird_housings = soup.find_all('article', class_='panel-listing-result listing-free ')\n",
    "    for housing in early_bird_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "#     Turn to next page and get more housings\n",
    "    if soup.find('ul',class_='navnext'):\n",
    "        if soup.find('ul',class_='navnext').find('a'):\n",
    "            next_page_token = soup.find('ul',class_='navnext').find('a').get('href')\n",
    "            next_page = 'https://www.spareroom.co.uk/flatshare/' + next_page_token\n",
    "        # Use recursion to get all the attractions    \n",
    "            housings_list.extend(get_housings(next_page))\n",
    "    return housings_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have find 732 results for you.\n"
     ]
    }
   ],
   "source": [
    "url_liver = 'https://www.spareroom.co.uk/flatshare/?search_id=746073457&'\n",
    "list_liver = get_housings(url_liver)\n",
    "print(f'We have find {len(list_liver)} results for you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(list_housings):\n",
    "    count = 0 \n",
    "    full_dict = dict()\n",
    "    for dict_info, link in list_housings:\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        # Request for details of each housing in NY\n",
    "        try:\n",
    "            results_page = requests.get(link)\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            soup = BeautifulSoup(results_page.content,'lxml')\n",
    "        except:\n",
    "            continue\n",
    "        # Get housing price for each room \n",
    "        price_list = list()\n",
    "        if soup.find('ul', class_='room-list'): \n",
    "            prices = soup.find('ul', class_='room-list')\n",
    "            price = prices.find_all('strong', class_='room-list__price')\n",
    "            for price_i in price:\n",
    "                price_list.append(price_i.get_text())\n",
    "        # price 这里似乎有个bug，但是我暂时懒得改\n",
    "        if soup.find('h3', class_='feature__heading'):\n",
    "            price_list.append(soup.find('h3', class_='feature__heading').get_text())\n",
    "        # Clean the data to remove 'Availability' in the price list\n",
    "        if 'Availability' in price_list:\n",
    "            price_list.remove('Availability')\n",
    "        dict_info['Price'] = price_list\n",
    "        # Get Availability for each housing\n",
    "        avail = soup.find('section', class_='feature feature--availability')\n",
    "        if avail:\n",
    "            all_info_avail = avail.find_all('dd', class_='feature-list__value')\n",
    "            availablility = all_info_avail[0].get_text()      \n",
    "            min_period = all_info_avail[1].get_text()      \n",
    "            max_period = all_info_avail[2].get_text() \n",
    "            dict_info['Availablility'] = availablility\n",
    "            dict_info['Min_period'] = min_period\n",
    "            dict_info['Max_period'] = max_period\n",
    "        # Get Amenities info for each housing\n",
    "        amenities = soup.find('section', class_='feature feature--amenities')\n",
    "        if amenities:\n",
    "            all_info_amenities = amenities.find_all('dd', class_='feature-list__value')\n",
    "            if all_info_amenities:\n",
    "                furnish = all_info_amenities[0].get_text()\n",
    "                dict_info['Furnishing'] = furnish\n",
    "        else:\n",
    "            dict_info['Furnishing'] = 'No info'\n",
    "        # Female/Male requirement\n",
    "        preference = soup.find('section', class_='feature feature--household-preferences')\n",
    "        if preference:\n",
    "            preference_info = preference.find_all('dt', class_='feature-list__key')\n",
    "            preference_detail = preference.find_all('dd', class_='feature-list__value')\n",
    "            if preference_info and preference_detail:\n",
    "                for info in preference_info:\n",
    "                    if info.get_text() == 'Gender':\n",
    "                        info_index = preference_info.index(info)\n",
    "                        break\n",
    "                try:\n",
    "                    gender = preference_detail[info_index].get_text() \n",
    "                    dict_info['Gender_requirement'] = gender\n",
    "                except:\n",
    "                    dict_info['Gender_requirement'] = 'No info'\n",
    "        full_dict[count] = dict_info\n",
    "        count = count + 1\n",
    "    return full_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_housings_liver = list_liver\n",
    "dict_liver = get_details(list_housings_liver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_liver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_liver.keys():\n",
    "    for subkey in dict_liver[key].keys():\n",
    "        if isinstance(dict_liver[key][subkey], str):\n",
    "            dict_liver[key][subkey] = dict_liver[key][subkey].lstrip().rstrip()\n",
    "# Clean the price list\n",
    "for key in dict_liver.keys():\n",
    "    list_in = list()\n",
    "    for item in list(dict_liver[key]['Price']):\n",
    "        list_in.append(item.strip('\\n'))\n",
    "    dict_liver[key]['Price'] = list_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create a dataframe to store the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_liver = pd.DataFrame(dict_liver)\n",
    "df_info_liver = df_info_liver.T\n",
    "\n",
    "# Fix furnished problem\n",
    "for i in df_info_liver.index:\n",
    "    if df_info_liver.iloc[i]['Furnishing'] in ['Furnished', 'Part Furnished', 'Unfurnished']:\n",
    "        pass\n",
    "    else:\n",
    "        df_info_liver.iloc[i]['Furnishing'] = 'No info'\n",
    "# Fix Gender_requirement problem\n",
    "for i in df_info_liver.index:\n",
    "    if not df_info_liver.iloc[i]['Gender_requirement'] in ['Males or females', 'Female preferred', 'No info',\n",
    "       'Male preferred']:\n",
    "        df_info_liver.iloc[i]['Gender_requirement'] = 'No info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new col in df_info_liver to store average price for a single person\n",
    "pattern = r'\\d+'  \n",
    "price_per_month = list()\n",
    "\n",
    "for i in df_info_liver.index:\n",
    "    list_in_price = list()\n",
    "    for item in df_info_liver.iloc[i]['Price']:\n",
    "        item = item.replace(',', '')\n",
    "        if 'pw' in item:\n",
    "            price_info = int((re.findall(pattern, item))[0])\n",
    "            list_in_price.append(price_info*4)\n",
    "        if 'pcm' in item:\n",
    "            price_info = int((re.findall(pattern, item))[0])\n",
    "            list_in_price.append(price_info)\n",
    "    price_per_month.append(list_in_price)\n",
    "price_per_month = np.array(price_per_month)\n",
    "df_info_liver['Price_per_month'] = price_per_month\n",
    "list_avg_price = list()\n",
    "for i in df_info_liver.index:\n",
    "    list_avg_price.append(np.mean(df_info_liver.iloc[i]['Price_per_month']) )\n",
    "df_info_liver['Average_price_per_month'] = np.array(list_avg_price)\n",
    "# Create a new col in df_info_liver to store zip code for each housing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new col for zip code\n",
    "list_pos = list()\n",
    "for i in df_info_liver.index:\n",
    "    for s in df_info.iloc[i]['Location']:\n",
    "        if s == '(':\n",
    "            position =df_info_liver.iloc[i]['Location'].index(s)\n",
    "            break\n",
    "    list_pos.append(df_info_liver.iloc[i]['Location'][position:].strip('(').strip(')'))\n",
    "df_info_liver['Postal_code'] = np.array(list_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')# seaborn is a style that have different colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To see if there is a gender preference in Liverpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group_liver = df_info_liver.groupby('Gender_requirement')\n",
    "gender_group_liver.size().plot(kind='bar', title='Gender requirement for rent in Liverpool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To see if there is more furnished apartment in Liverpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furnish_group_liver = df_info_liver.groupby('Furnishing')\n",
    "furnish_group_liver.size().plot(kind='bar', title='Furnishing status of housing in Liverpool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To see the size distribution in Liverpool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_group_liver = df_info_liver.groupby('Size')\n",
    "size_group_liver.size().plot(kind='bar', title='Housing size in Liverpool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To see the average per-month price change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_liver['Average_price_per_month'].plot(kind='line', title='Average price in Liverpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the average price\n",
    "def GroupColFunc(df, ind, col):\n",
    "    if df[col].loc[ind] < 500:\n",
    "        return 'Lower than 500'\n",
    "    elif 1000 > df[col].loc[ind] >= 500:\n",
    "        return 'Between 500 and 1000'\n",
    "    else:\n",
    "        return 'Above 1000'\n",
    "avg_price_group_liver = df_info_liver.groupby(lambda x: GroupColFunc(df_info, x, 'Average_price_per_month')) \n",
    "avg_price_group_liver.size().plot(kind='bar', title='Housing average price in London')\n",
    "# Add a col of average price group for further analysis\n",
    "avg_price_list = list()\n",
    "for i in df_info_liver.index:\n",
    "    avg_price_list.append(GroupColFunc(df_info, i, 'Average_price_per_month'))\n",
    "df_info_liver['Avg_price_group'] = np.array(avg_price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by both size and average price\n",
    "size_avg_groups_liver = df_info_liver.groupby(['Size','Avg_price_group']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NUM = 2\n",
    "ROW_NUM = 2\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(ROW_NUM, COL_NUM, figsize=(12,12))\n",
    "\n",
    "for i, (avg, size) in enumerate(size_avg_groups_liver.items()): \n",
    "    ax = axes[int(i/COL_NUM), i%COL_NUM]\n",
    "    size = size.sort_values(ascending=False) # sort the data in descending order \n",
    "    size.plot(kind='barh', ax=ax)\n",
    "    ax.set_title(avg)\n",
    "\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Manchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
