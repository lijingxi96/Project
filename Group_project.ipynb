{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpareRoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Web Scraping housing info in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housings(url): \n",
    "    housings_list = list()\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Request for home page of NY housing info\n",
    "    try:\n",
    "        results_page = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(results_page.content,'lxml')\n",
    "    except:\n",
    "        return None\n",
    "    # Get all the feature housings and bold housings on the first page\n",
    "    feature_housings = soup.find_all('article',class_='panel-listing-result listing-featured ')\n",
    "    for housing in feature_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "    # Second Type of housing\n",
    "    all_housings = soup.find_all('article', class_='panel-listing-result listing-bold ')\n",
    "    for housing in all_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "    # Third type of housing:\n",
    "    early_bird_housings = soup.find_all('article', class_='panel-listing-result listing-free ')\n",
    "    for housing in early_bird_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "#     Turn to next page and get more housings\n",
    "    if soup.find('ul',class_='navnext'):\n",
    "        if soup.find('ul',class_='navnext').find('a'):\n",
    "            next_page_token = soup.find('ul',class_='navnext').find('a').get('href')\n",
    "            next_page = 'https://www.spareroom.co.uk/flatshare/' + next_page_token\n",
    "        # Use recursion to get all the attractions    \n",
    "            housings_list.extend(get_housings(next_page))\n",
    "    return housings_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have find 1098 results for you.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.spareroom.co.uk/flatshare/?search_id=745817425&'\n",
    "list_ = get_housings(url)\n",
    "print(f'We have find {len(list_)} results for you.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(list_housings):\n",
    "    count = 0 \n",
    "    full_dict = dict()\n",
    "    for dict_info, link in list_housings:\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        # Request for details of each housing in NY\n",
    "        try:\n",
    "            results_page = requests.get(link)\n",
    "        except:\n",
    "            return None\n",
    "        try:\n",
    "            soup = BeautifulSoup(results_page.content,'lxml')\n",
    "        except:\n",
    "            return None\n",
    "        # Get housing price for each room \n",
    "        price_list = list()\n",
    "        if soup.find('ul', class_='room-list'): \n",
    "            prices = soup.find('ul', class_='room-list')\n",
    "            price = prices.find_all('strong', class_='room-list__price')\n",
    "            for price_i in price:\n",
    "                price_list.append(price_i.get_text())\n",
    "        # price 这里似乎有个bug，但是我暂时懒得改\n",
    "        if soup.find('h3', class_='feature__heading'):\n",
    "            price_list.append(soup.find('h3', class_='feature__heading').get_text())\n",
    "        # Clean the data to remove 'Availability' in the price list\n",
    "        if 'Availability' in price_list:\n",
    "            price_list.remove('Availability')\n",
    "        dict_info['Price'] = price_list\n",
    "        # Get Availability for each housing\n",
    "        avail = soup.find('section', class_='feature feature--availability')\n",
    "        if avail:\n",
    "            all_info_avail = avail.find_all('dd', class_='feature-list__value')\n",
    "            availablility = all_info_avail[0].get_text()      \n",
    "            min_period = all_info_avail[1].get_text()      \n",
    "            max_period = all_info_avail[2].get_text() \n",
    "            dict_info['Availablility'] = availablility\n",
    "            dict_info['Min_period'] = min_period\n",
    "            dict_info['Max_period'] = max_period\n",
    "        # Get Amenities info for each housing\n",
    "        amenities = soup.find('section', class_='feature feature--amenities')\n",
    "        all_info_amenities = amenities.find_all('dd', class_='feature-list__value')\n",
    "        if all_info_amenities:\n",
    "            furnish = all_info_amenities[0].get_text()\n",
    "            dict_info['Furnishing'] = furnish\n",
    "        # Female/Male requirement\n",
    "        preference = soup.find('section', class_='feature feature--household-preferences')\n",
    "        preference_info = preference.find_all('dt', class_='feature-list__key')\n",
    "        preference_detail = preference.find_all('dd', class_='feature-list__value')\n",
    "        if preference_info and preference_detail:\n",
    "            for info in preference_info:\n",
    "                if info.get_text() == 'Gender':\n",
    "                    info_index = preference_info.index(info)\n",
    "                    break\n",
    "            try:\n",
    "                gender = preference_detail[info_index].get_text() \n",
    "                dict_info['Gender_requirement'] = gender\n",
    "            except:\n",
    "                dict_info['Gender_requirement'] = 'No info'\n",
    "        full_dict[count] = dict_info\n",
    "        count = count + 1\n",
    "    return full_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3e33a0d47fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_housings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_housings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-a9b32db33713>\u001b[0m in \u001b[0;36mget_details\u001b[0;34m(list_housings)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Get Amenities info for each housing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mamenities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'section'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'feature feature--amenities'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mall_info_amenities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamenities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'feature-list__value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall_info_amenities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mfurnish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_info_amenities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "list_housings = list_\n",
    "dict_ = get_details(list_housings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Liverpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housings(url): \n",
    "    housings_list = list()\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Request for home page of NY housing info\n",
    "    try:\n",
    "        results_page = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(results_page.content,'lxml')\n",
    "    except:\n",
    "        return None\n",
    "    # Get all the feature housings and bold housings on the first page\n",
    "    feature_housings = soup.find_all('article',class_='panel-listing-result listing-featured ')\n",
    "    for housing in feature_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "    # Second type\n",
    "    all_housings = soup.find_all('article', class_='panel-listing-result listing-bold ')\n",
    "    for housing in all_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "    # Third type\n",
    "    early_bird_housings = soup.find_all('article', class_='panel-listing-result listing-free ')\n",
    "    for housing in early_bird_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "#     Turn to next page and get more housings\n",
    "    if soup.find('ul',class_='navnext'):\n",
    "        if soup.find('ul',class_='navnext').find('a'):\n",
    "            next_page_token = soup.find('ul',class_='navnext').find('a').get('href')\n",
    "            next_page = 'https://www.spareroom.co.uk/flatshare/' + next_page_token\n",
    "        # Use recursion to get all the attractions    \n",
    "            housings_list.extend(get_housings(next_page))\n",
    "    return housings_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have find 732 results for you.\n"
     ]
    }
   ],
   "source": [
    "url_liver = 'https://www.spareroom.co.uk/flatshare/?search_id=746073457&'\n",
    "list_liver = get_housings(url_liver)\n",
    "print(f'We have find {len(list_liver)} results for you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(list_housings):\n",
    "    count = 0 \n",
    "    full_dict = dict()\n",
    "    for dict_info, link in list_housings:\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        # Request for details of each housing in NY\n",
    "        try:\n",
    "            results_page = requests.get(link)\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            soup = BeautifulSoup(results_page.content,'lxml')\n",
    "        except:\n",
    "            continue\n",
    "        # Get housing price for each room \n",
    "        price_list = list()\n",
    "        if soup.find('ul', class_='room-list'): \n",
    "            prices = soup.find('ul', class_='room-list')\n",
    "            price = prices.find_all('strong', class_='room-list__price')\n",
    "            for price_i in price:\n",
    "                price_list.append(price_i.get_text())\n",
    "        # price 这里似乎有个bug，但是我暂时懒得改\n",
    "        if soup.find('h3', class_='feature__heading'):\n",
    "            price_list.append(soup.find('h3', class_='feature__heading').get_text())\n",
    "        # Clean the data to remove 'Availability' in the price list\n",
    "        if 'Availability' in price_list:\n",
    "            price_list.remove('Availability')\n",
    "        dict_info['Price'] = price_list\n",
    "        # Get Availability for each housing\n",
    "        avail = soup.find('section', class_='feature feature--availability')\n",
    "        if avail:\n",
    "            all_info_avail = avail.find_all('dd', class_='feature-list__value')\n",
    "            availablility = all_info_avail[0].get_text()      \n",
    "            min_period = all_info_avail[1].get_text()      \n",
    "            max_period = all_info_avail[2].get_text() \n",
    "            dict_info['Availablility'] = availablility\n",
    "            dict_info['Min_period'] = min_period\n",
    "            dict_info['Max_period'] = max_period\n",
    "        # Get Amenities info for each housing\n",
    "        amenities = soup.find('section', class_='feature feature--amenities')\n",
    "        if amenities:\n",
    "            all_info_amenities = amenities.find_all('dd', class_='feature-list__value')\n",
    "            if all_info_amenities:\n",
    "                furnish = all_info_amenities[0].get_text()\n",
    "                dict_info['Furnishing'] = furnish\n",
    "        else:\n",
    "            dict_info['Furnishing'] = 'No info'\n",
    "        # Female/Male requirement\n",
    "        preference = soup.find('section', class_='feature feature--household-preferences')\n",
    "        if preference:\n",
    "            preference_info = preference.find_all('dt', class_='feature-list__key')\n",
    "            preference_detail = preference.find_all('dd', class_='feature-list__value')\n",
    "            if preference_info and preference_detail:\n",
    "                for info in preference_info:\n",
    "                    if info.get_text() == 'Gender':\n",
    "                        info_index = preference_info.index(info)\n",
    "                        break\n",
    "                try:\n",
    "                    gender = preference_detail[info_index].get_text() \n",
    "                    dict_info['Gender_requirement'] = gender\n",
    "                except:\n",
    "                    dict_info['Gender_requirement'] = 'No info'\n",
    "        full_dict[count] = dict_info\n",
    "        count = count + 1\n",
    "    return full_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_housings_liver = list_liver\n",
    "dict_liver = get_details(list_housings_liver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_liver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Manchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
