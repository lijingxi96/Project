{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpareRoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5b206e11854f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Web Scraping housing info in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housings(url): \n",
    "    housings_list = list()\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Request for home page of NY housing info\n",
    "    try:\n",
    "        results_page = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(results_page.content,'lxml')\n",
    "    except:\n",
    "        return None\n",
    "    # Get all the feature housings and bold housings on the first page\n",
    "    feature_housings = soup.find_all('article',class_='panel-listing-result listing-featured ')\n",
    "    for housing in feature_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "    # Second Type of housing\n",
    "    all_housings = soup.find_all('article', class_='panel-listing-result listing-bold ')\n",
    "    for housing in all_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "    # Third type of housing:\n",
    "    early_bird_housings = soup.find_all('article', class_='panel-listing-result listing-free ')\n",
    "    for housing in early_bird_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "            housings_list.append([detail_dict,link])\n",
    "#     Turn to next page and get more housings\n",
    "    if soup.find('ul',class_='navnext'):\n",
    "        if soup.find('ul',class_='navnext').find('a'):\n",
    "            next_page_token = soup.find('ul',class_='navnext').find('a').get('href')\n",
    "            next_page = 'https://www.spareroom.co.uk/flatshare/' + next_page_token\n",
    "        # Use recursion to get all the attractions    \n",
    "            housings_list.extend(get_housings(next_page))\n",
    "    return housings_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_london = 'https://www.spareroom.co.uk/flatshare/?search_id=745817425&'\n",
    "list_ = get_housings(url_london)\n",
    "print(f'We have find {len(list_)} results for you.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(list_housings):\n",
    "    count = 0 \n",
    "    full_dict = dict()\n",
    "    for dict_info, link in list_housings:\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        # Request for details of each housing in NY\n",
    "        try:\n",
    "            results_page = requests.get(link)\n",
    "        except:\n",
    "            return None\n",
    "        try:\n",
    "            soup = BeautifulSoup(results_page.content,'lxml')\n",
    "        except:\n",
    "            return None\n",
    "        # Get housing price for each room \n",
    "        price_list = list()\n",
    "        if soup.find('ul', class_='room-list'): \n",
    "            prices = soup.find('ul', class_='room-list')\n",
    "            price = prices.find_all('strong', class_='room-list__price')\n",
    "            for price_i in price:\n",
    "                price_list.append(price_i.get_text())\n",
    "        # price 这里似乎有个bug，但是我暂时懒得改\n",
    "        if soup.find('h3', class_='feature__heading'):\n",
    "            price_list.append(soup.find('h3', class_='feature__heading').get_text())\n",
    "        # Clean the data to remove 'Availability' in the price list\n",
    "        if 'Availability' in price_list:\n",
    "            price_list.remove('Availability')\n",
    "        dict_info['Price'] = price_list\n",
    "        # Get Availability for each housing\n",
    "        avail = soup.find('section', class_='feature feature--availability')\n",
    "        if avail:\n",
    "            all_info_avail = avail.find_all('dd', class_='feature-list__value')\n",
    "            availablility = all_info_avail[0].get_text()      \n",
    "            min_period = all_info_avail[1].get_text()      \n",
    "            max_period = all_info_avail[2].get_text() \n",
    "            dict_info['Availablility'] = availablility\n",
    "            dict_info['Min_period'] = min_period\n",
    "            dict_info['Max_period'] = max_period\n",
    "        # Get Amenities info for each housing\n",
    "        amenities = soup.find('section', class_='feature feature--amenities')\n",
    "        if amenities:\n",
    "            all_info_amenities = amenities.find_all('dd', class_='feature-list__value')\n",
    "            if all_info_amenities:\n",
    "                furnish = all_info_amenities[0].get_text()\n",
    "                dict_info['Furnishing'] = furnish\n",
    "        else:\n",
    "            dict_info['Furnishing'] = 'No info'\n",
    "        # Female/Male requirement\n",
    "        preference = soup.find('section', class_='feature feature--household-preferences')\n",
    "        if preference:\n",
    "            preference_info = preference.find_all('dt', class_='feature-list__key')\n",
    "            preference_detail = preference.find_all('dd', class_='feature-list__value')\n",
    "            if preference_info and preference_detail:\n",
    "                for info in preference_info:\n",
    "                    if info.get_text() == 'Gender':\n",
    "                        info_index = preference_info.index(info)\n",
    "                        break\n",
    "                try:\n",
    "                    gender = preference_detail[info_index].get_text() \n",
    "                    dict_info['Gender_requirement'] = gender\n",
    "                except:\n",
    "                    dict_info['Gender_requirement'] = 'No info'\n",
    "        full_dict[count] = dict_info\n",
    "        count = count + 1\n",
    "    return full_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_housings = list_\n",
    "dict_ = get_details(list_housings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_.keys():\n",
    "    for subkey in dict_[key].keys():\n",
    "        if isinstance(dict_[key][subkey], str):\n",
    "            dict_[key][subkey] = dict_[key][subkey].lstrip().rstrip()\n",
    "# Clean the price list\n",
    "for key in dict_.keys():\n",
    "    list_in = list()\n",
    "    for item in list(dict_[key]['Price']):\n",
    "        list_in.append(item.strip('\\n'))\n",
    "    dict_[key]['Price'] = list_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create a dataframe to store the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(dict_)\n",
    "df_info = df_info.T\n",
    "\n",
    "# Fix furnished problem\n",
    "for i in df_info.index:\n",
    "    if df_info.iloc[i]['Furnishing'] in ['Furnished', 'Part Furnished', 'Unfurnished']:\n",
    "        pass\n",
    "    else:\n",
    "        df_info.iloc[i]['Furnishing'] = 'No info'\n",
    "# Fix Gender_requirement problem\n",
    "for i in df_info.index:\n",
    "    if not df_info.iloc[i]['Gender_requirement'] in ['Males or females', 'Female preferred', 'No info',\n",
    "       'Male preferred']:\n",
    "        df_info.iloc[i]['Gender_requirement'] = 'No info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new col in df_info to store average price for a single person\n",
    "pattern = r'\\d+'  \n",
    "price_per_month = list()\n",
    "\n",
    "for i in df_info.index:\n",
    "    list_in_price = list()\n",
    "    for item in df_info.iloc[i]['Price']:\n",
    "        item = item.replace(',', '')\n",
    "        if 'pw' in item:\n",
    "            price_info = int((re.findall(pattern, item))[0])\n",
    "            list_in_price.append(price_info*4)\n",
    "        if 'pcm' in item:\n",
    "            price_info = int((re.findall(pattern, item))[0])\n",
    "            list_in_price.append(price_info)\n",
    "    price_per_month.append(list_in_price)\n",
    "price_per_month = np.array(price_per_month)\n",
    "df_info['Price_per_month'] = price_per_month\n",
    "list_avg_price = list()\n",
    "for i in df_info.index:\n",
    "    list_avg_price.append(np.mean(df_info.iloc[i]['Price_per_month']) )\n",
    "df_info['Average_price_per_month'] = np.array(list_avg_price)\n",
    "# Create a new col in df_info to store zip code for each housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new col for zip code\n",
    "list_pos = list()\n",
    "for i in df_info.index:\n",
    "    for s in df_info.iloc[i]['Location']:\n",
    "        if s == '(':\n",
    "            position = df_info.iloc[i]['Location'].index(s)\n",
    "            break\n",
    "    list_pos.append(df_info.iloc[i]['Location'][position:].strip('(').strip(')'))\n",
    "df_info['Postal_code'] = np.array(list_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')# seaborn is a style that have different colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see if there is a gender preference in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group = df_info.groupby('Gender_requirement')\n",
    "gender_group.size().plot(kind='bar', title='Gender requirement for rent in London')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see the housing condition in postal code area in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Postal_code_group = df_info.groupby('Postal_code')\n",
    "Postal_code_group.size().plot(kind='bar', title='Postal code area in London', figsize=(24,24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see if there is more furnished apartment in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furnish_group = df_info.groupby('Furnishing')\n",
    "furnish_group.size().plot(kind='bar', title='Furnishing status of housing in London')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> To see the size distribution in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_group = df_info.groupby('Size')\n",
    "size_group.size().plot(kind='bar', title='Housing size in London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Liverpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housings(url): \n",
    "    housings_list = list()\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Request for home page of NY housing info\n",
    "    try:\n",
    "        results_page = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(results_page.content,'lxml')\n",
    "    except:\n",
    "        return None\n",
    "    # Get all the feature housings and bold housings on the first page\n",
    "    feature_housings = soup.find_all('article',class_='panel-listing-result listing-featured ')\n",
    "    for housing in feature_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "    # Second type\n",
    "    all_housings = soup.find_all('article', class_='panel-listing-result listing-bold ')\n",
    "    for housing in all_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "    # Third type\n",
    "    early_bird_housings = soup.find_all('article', class_='panel-listing-result listing-free ')\n",
    "    for housing in early_bird_housings:\n",
    "        if housing.find('a'):\n",
    "            detail_dict = dict()\n",
    "            name = housing.find('h1').get_text()\n",
    "            size = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").get_text()\n",
    "            detail_dict['Short_description'] = name\n",
    "            location = housing.find('div', class_='pricingInfo').find('em',class_=\"shortDescription\").find('span', class_='listingLocation').get_text()\n",
    "            # Split the room size and the location and store only size\n",
    "            for i in range(1,len(size)):\n",
    "                if size[i].isupper(): \n",
    "                    position = i\n",
    "                    break\n",
    "            detail_dict['Size'] = size[:position]\n",
    "            detail_dict['Location'] = location\n",
    "            link = 'https://www.spareroom.co.uk' + housing.find('a').get('href')\n",
    "        housings_list.append([detail_dict,link])\n",
    "#     Turn to next page and get more housings\n",
    "    if soup.find('ul',class_='navnext'):\n",
    "        if soup.find('ul',class_='navnext').find('a'):\n",
    "            next_page_token = soup.find('ul',class_='navnext').find('a').get('href')\n",
    "            next_page = 'https://www.spareroom.co.uk/flatshare/' + next_page_token\n",
    "        # Use recursion to get all the attractions    \n",
    "            housings_list.extend(get_housings(next_page))\n",
    "    return housings_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have find 732 results for you.\n"
     ]
    }
   ],
   "source": [
    "url_liver = 'https://www.spareroom.co.uk/flatshare/?search_id=746073457&'\n",
    "list_liver = get_housings(url)\n",
    "print(f'We have find {len(list_liver)} results for you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(list_housings):\n",
    "    count = 0 \n",
    "    full_dict = dict()\n",
    "    for dict_info, link in list_housings:\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        # Request for details of each housing in NY\n",
    "        try:\n",
    "            results_page = requests.get(link)\n",
    "        except:\n",
    "            return None\n",
    "        try:\n",
    "            soup = BeautifulSoup(results_page.content,'lxml')\n",
    "        except:\n",
    "            return None\n",
    "        # Get housing price for each room \n",
    "        price_list = list()\n",
    "        if soup.find('ul', class_='room-list'): \n",
    "            prices = soup.find('ul', class_='room-list')\n",
    "            price = prices.find_all('strong', class_='room-list__price')\n",
    "            for price_i in price:\n",
    "                price_list.append(price_i.get_text())\n",
    "        # price 这里似乎有个bug，但是我暂时懒得改\n",
    "        if soup.find('h3', class_='feature__heading'):\n",
    "            price_list.append(soup.find('h3', class_='feature__heading').get_text())\n",
    "        # Clean the data to remove 'Availability' in the price list\n",
    "        if 'Availability' in price_list:\n",
    "            price_list.remove('Availability')\n",
    "        dict_info['Price'] = price_list\n",
    "        # Get Availability for each housing\n",
    "        avail = soup.find('section', class_='feature feature--availability')\n",
    "        if avail:\n",
    "            all_info_avail = avail.find_all('dd', class_='feature-list__value')\n",
    "            availablility = all_info_avail[0].get_text()      \n",
    "            min_period = all_info_avail[1].get_text()      \n",
    "            max_period = all_info_avail[2].get_text() \n",
    "            dict_info['Availablility'] = availablility\n",
    "            dict_info['Min_period'] = min_period\n",
    "            dict_info['Max_period'] = max_period\n",
    "        # Get Amenities info for each housing\n",
    "        amenities = soup.find('section', class_='feature feature--amenities')\n",
    "        all_info_amenities = amenities.find_all('dd', class_='feature-list__value')\n",
    "        if all_info_amenities:\n",
    "            furnish = all_info_amenities[0].get_text()\n",
    "            dict_info['Furnishing'] = furnish\n",
    "        # Female/Male requirement\n",
    "        preference = soup.find('section', class_='feature feature--household-preferences')\n",
    "        preference_info = preference.find_all('dt', class_='feature-list__key')\n",
    "        preference_detail = preference.find_all('dd', class_='feature-list__value')\n",
    "        if preference_info and preference_detail:\n",
    "            for info in preference_info:\n",
    "                if info.get_text() == 'Gender':\n",
    "                    info_index = preference_info.index(info)\n",
    "                    break\n",
    "            try:\n",
    "                gender = preference_detail[info_index].get_text() \n",
    "                dict_info['Gender_requirement'] = gender\n",
    "            except:\n",
    "                dict_info['Gender_requirement'] = 'No info'\n",
    "        full_dict[count] = dict_info\n",
    "        count = count + 1\n",
    "    return full_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3e33a0d47fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_housings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_housings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-a9b32db33713>\u001b[0m in \u001b[0;36mget_details\u001b[0;34m(list_housings)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Get Amenities info for each housing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mamenities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'section'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'feature feature--amenities'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mall_info_amenities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamenities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'feature-list__value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall_info_amenities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mfurnish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_info_amenities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "list_housings_liver = list_liver\n",
    "dict_liver = get_details(list_housings_liver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Manchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
